---
title: "(Quickly) Evaluating expressions"
template: "post.html"
date: 2024-11-23
draft: true
tags:
- algorithms
description: "Quickly evaluating expressions"
---

I ran into this problem trying to complete a benchmark for a paper I was working on for my MS thesis - I had around 500 Megs of data for an instrumentation point, representing the values of variables at that instrumentation point, and I had to validate a bunch of invariants on this data.

Wait what?

## The problem

The problem statement is quite simple. Imagine we have a list of expressions, which look like this:

$$
\begin{aligned}
&x = y + z \\\
&x = min(y, 0) \times z \\\
&x\ \\% \ 59 = min(y, z) + 240 \\\
\end{aligned}
$$

And a bunch of data points that look like this:

| y | z | x |
|---|---|---|
| 1 | 2 | 3 |
| 4 | 5 | 6 |
| 7 | 8 | 9 |

Which of these expressions are true for the data points? We can clearly see, for the first data point, the first expression is true, but the second and third are not. For the second data point, none of the expressions are true. And so on.

Now the real problem is this table is large. Very very large. 11 million rows large. And I have these expressions that get dynamically generated by dynamic invariant generation tools like [DIG]() and [Daikon](). The rule is:

> For an expression to be valid, it must return _true_ for all data points.

The target is to cull this list of expressions to a list that contains only valid expressions. For the remainder of this article, "expressions" and "invariants" may be used interchangeably.


## Baselines

You cannot improve what you cannot measure. So let's start by measuring the time it takes to evaluate these expressions. I will be performing all baseline measurements against a "compiled" python eval AST expression, which takes each data point and evaluates the expression against it. For now, we will validate the expression against _all_ data points even if it fails for any one of them for measurement's sake. 

I am shamelessly stealing https://www.bitsofbits.com/2014/09/21/numpy-micro-optimization-and-numexpr/'s method of benchmarking (considering the cache limitations, it might be interesting to see some results).

I have 3 sizes of data. Working on my M3 macbook, I seem to have a 16MiB L2 cache, so I will be using 16MiB as the "small" data size, 64MiB as the "medium" data size, and 256MiB as the "large" data size. The expressions to be used are listed below, and all data inputs are generated randomly.

### Baseline results

## Evaluating the baseline on Rust

## Writing a small expression interpreting VM

## Writing a small expression JIT compiler

## Checking out SIMD

## Conclusion
