<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Writing (rewriting) a lexer | Bhusal's </title> <meta name="author" content="Sandesh Bhusal"> <meta name="description" content="A journey of writing a lexer for a simple language in Rust."> <meta name="keywords" content="sandesh-bhusal,sandesh,bhusal,blog"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Spline+Sans+Mono:ital,wght@0,300..700;1,300..700|Material+Icons|PT+Serif:ital,wght@0,400;0,700;1,400;1,700|Inter:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sandeshbhusal.github.io/blog/2024/lexers/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Bhusal's </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Writing (rewriting) a lexer</h1> <p class="post-meta"> Created in November 20, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> ¬† ¬∑ ¬† <a href="/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> algorithms</a> ¬† <a href="/blog/tag/programming-languages"> <i class="fa-solid fa-hashtag fa-sm"></i> programming languages</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I‚Äôve been working on a very small expression evaluation engine for my project <a href="https://github.com/sandeshbhusal/Hulaak" rel="external nofollow noopener" target="_blank">Hulaak</a> for quite a bit now. Aptly, the expression evaluation language is called Hulang, and it‚Äôs a very simple language that works on JSON documents to modify them, kind of like what <a href="https://jqlang.github.io/jq/" rel="external nofollow noopener" target="_blank">jq</a> does. The language implementation is still in its infancy, but I‚Äôve been working on it on and off for a few days now, and this is my kinda-sorta journey of writing a lexer for the language.</p> <h2 id="before-you-proceed">Before you proceed</h2> <p>This post is quite code-heavy as I expect the posts in this series to be. All implementation is done in Rust, but should be portable to other languages with minimal changes. I will be using Rust‚Äôs <code class="language-plaintext highlighter-rouge">regex</code> crate for the first implementation, and then move on to a more conventional implementation. The code snippets are not complete, and are meant to be illustrative of the concepts I am discussing. The complete code can be found in the <a href="https://gist.github.com/sandeshbhusal/5de659c5081b42eaf668e1e5bf090feb" rel="external nofollow noopener" target="_blank">gist</a> at the end of the post.</p> <h2 id="the-theory">The theory</h2> <p>From my PL course, I remember that the purpose of a lexer is to:</p> <blockquote> <p>Take the input string and convert it into a stream of tokens.</p> </blockquote> <p>This does not really matter a whole lot when you‚Äôre working with a small stream of input; for a language like Hulang, it‚Äôs pretty trivial to implement this with Regexes. But considering the overengineer that I am, I wanted to implement a lexer that I could reuse for projects that I <em>might</em> work on in the future üòâ.</p> <p>A lexer is a giant combined NFA, from my PL course. The NFA matches over the given input string, landing in ‚Äúaccept‚Äù states as it goes on, and the tokens are generated from the accept states. Once there is a single accept state, the lexer knows that it has found a token, and it can generate the token from the accept state. If there are multiple accept states, it is ambigious, since we do not know what kind of token we should emit. In that case, we can do the following:</p> <ul> <li>Choose the longest match, and emit the token from that state.</li> <li>If there are multiple longest matches, have precedence rules in-place so that we can select a single one..</li> </ul> <pre><code class="language-mermaid">stateDiagram-v2
    [*] --&gt; S0
    S0: Start State
    
    %% Path for identifiers starting with 'i'
    S0 --&gt; S1: i
    S1: After 'i'
    S1 --&gt; S2: f
    S1 --&gt; ID: a-z
    S1 --&gt; [*]: end input
    
    %% Path for all other identifiers
    S0 --&gt; ID: a-z
    
    %% State for 'if' keyword
    S2: Keyword 'if'
    S2 --&gt; ID: a-z
    S2 --&gt; [*]: end input
    
    %% Identifier state
    ID: Identifier
    ID --&gt; ID: a-z
    ID --&gt; [*]: end input
</code></pre> <p>Considering the NFA above, if the input is ‚Äúap‚Äù, then we land in the ‚ÄúIdentifier‚Äù state, and we can emit an identifier. If we have a ‚Äúif‚Äù, however, we land in <em>both</em> the ‚ÄúIdentifier‚Äù and the ‚ÄúKeyword ‚Äòif‚Äô‚Äù states. In this case, we can choose the longest match, which is ‚Äú‚Äòif‚Äô‚Äù, and then order by precedence rule to get keyword ‚Äúif‚Äù and not identifier ‚Äúif‚Äù. If there is an input of ‚Äúifa‚Äù, we get ‚Äúif‚Äù as the longest match at length 2, but if we continue to match, we eventually only have ‚Äúifa‚Äù as an identifier, and do not emit ‚Äúkeyword if‚Äù followed by ‚Äúidentifier a‚Äù.</p> <h2 id="brute-implementation-in-rust">Brute implementation in Rust.</h2> <p>I know and love Rust, so I will be making a very simple implementation in Rust itself. The format can be extended to support multiple tokens, and symbols, but for now we‚Äôll just work with three things - a ‚Äú.‚Äù token, ‚Äúif‚Äù keyword and ‚Äúidentifier‚Äù.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">TokenType</span> <span class="p">{</span>
    <span class="n">Identifier</span><span class="p">,</span>
    <span class="n">Dot</span><span class="p">,</span>
    <span class="n">If</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <p>Each of these token types will have an accompanying <code class="language-plaintext highlighter-rouge">Regex</code> pattern. We will make this pattern static.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="n">PATTERN_MAP</span><span class="p">:</span> <span class="n">LazyLock</span><span class="o">&lt;</span><span class="n">IndexMap</span><span class="o">&lt;&amp;</span><span class="k">'static</span> <span class="nb">str</span><span class="p">,</span> <span class="n">TokenType</span><span class="o">&gt;&gt;</span> <span class="o">=</span> <span class="nn">LazyLock</span><span class="p">::</span><span class="nf">new</span><span class="p">(||</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">map</span> <span class="o">=</span> <span class="nn">IndexMap</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
    <span class="k">for</span> <span class="n">variant</span> <span class="k">in</span> <span class="nn">TokenType</span><span class="p">::</span><span class="nf">iter</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">pattern</span> <span class="o">=</span> <span class="k">match</span> <span class="n">variant</span> <span class="p">{</span>
            <span class="nn">TokenType</span><span class="p">::</span><span class="n">Dot</span> <span class="k">=&gt;</span> <span class="s">r"\."</span><span class="p">,</span>
            <span class="nn">TokenType</span><span class="p">::</span><span class="n">If</span> <span class="k">=&gt;</span> <span class="s">r"if"</span><span class="p">,</span>
            <span class="nn">TokenType</span><span class="p">::</span><span class="n">Identifier</span> <span class="k">=&gt;</span> <span class="s">r"[a-zA-Z]+"</span><span class="p">,</span>
        <span class="p">};</span>

        <span class="n">map</span><span class="nf">.insert</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">variant</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">map</span>
<span class="p">});</span>
</code></pre></div></div> <p>The tokens will be placed in a <code class="language-plaintext highlighter-rouge">Token</code> struct that marks the start, end, and content of the tokens (I know Rust has tagged unions that can hold data, but I like this way better).</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Token</span> <span class="p">{</span>
    <span class="n">start</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
    <span class="n">token_type</span><span class="p">:</span> <span class="n">TokenType</span><span class="p">,</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <p>The Token type does heap allocation for the content, but I will omit using lifetimes for readability. The lexer will be a struct that holds the input string and the current position in the input string.</p> <h2 id="the-regex-lexer">The regex lexer</h2> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">lexer</span><span class="p">(</span><span class="n">input</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">(</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">String</span><span class="p">)</span><span class="o">&gt;</span> <span class="p">{</span>
<span class="p">}</span>
</code></pre></div></div> <p>With this, we have the outline of a lexer that can match tokens and return them. The function takes in a string and returns a result that returns either:</p> <ul> <li>A successful result with a vector of tokens.</li> <li>An error with a vector of tokens that were successfully matched, and the remaining input string that was not matched.</li> </ul> <p>Now from the <a href="#the-theory">Theory</a>, we know that we need a giant DFA that will encompass all rules, and help us with the matching process. We can implement this giant DFA as a <a href="https://docs.rs/regex/latest/regex/struct.RegexSet.html" rel="external nofollow noopener" target="_blank">RegexSet</a> type that gives us the ability to match multiple regexes at once. We can then iterate over the matches and choose the longest match.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">lexer</span><span class="p">(</span><span class="n">input</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">(</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">String</span><span class="p">)</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">token</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">regex_dfa</span> <span class="o">=</span> <span class="nn">RegexSet</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">PATTERN_MAP</span><span class="nf">.keys</span><span class="p">())</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <p>Now the matching can begin. The algorithm goes like this:</p> <ol> <li>While the input string has a whitespace, skip the whitespace, and find an actual character we can start matching from.</li> <li>While the offset is less than the input string length, we can match tokens.</li> <li>Match the regex set with the input string, and get the longest match at the offset.</li> <li>If there is no match, return an error with the tokens matched so far, and the remaining input string.</li> </ol> <p>The code looks like this:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">fn</span> <span class="nf">lexer</span><span class="p">(</span><span class="n">input</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">(</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">String</span><span class="p">)</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">tokens</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">regex_dfa</span> <span class="o">=</span> <span class="nn">RegexSet</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">PATTERN_MAP</span><span class="nf">.keys</span><span class="p">())</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="k">while</span> <span class="n">offset</span> <span class="o">&lt;</span> <span class="n">input</span><span class="nf">.len</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">((</span><span class="n">off</span><span class="p">,</span> <span class="n">_</span><span class="p">))</span> <span class="o">=</span> <span class="n">input</span>
            <span class="nf">.chars</span><span class="p">()</span>
            <span class="nf">.enumerate</span><span class="p">()</span>
            <span class="nf">.find</span><span class="p">(|(</span><span class="n">off</span><span class="p">,</span> <span class="n">ip</span><span class="p">)|</span> <span class="o">*</span><span class="n">off</span> <span class="o">&gt;=</span> <span class="n">offset</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">ip</span><span class="nf">.is_whitespace</span><span class="p">())</span>
        <span class="p">{</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">off</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nf">Ok</span><span class="p">(</span><span class="n">tokens</span><span class="p">);</span> <span class="c1">// Nothing except whitespaces found. Return lexed this far.</span>
        <span class="p">}</span>

        <span class="c1">// Get all matches for the current offset.</span>
        <span class="k">let</span> <span class="n">matched_patterns_index</span> <span class="o">=</span> <span class="n">regex_dfa</span><span class="nf">.matches</span><span class="p">(</span><span class="o">&amp;</span><span class="n">input</span><span class="p">[</span><span class="n">offset</span><span class="o">..</span><span class="p">]);</span>
        <span class="k">if</span> <span class="n">matched_patterns_index</span><span class="nf">.len</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nf">Err</span><span class="p">((</span><span class="n">tokens</span><span class="p">,</span> <span class="p">(</span><span class="o">&amp;</span><span class="n">input</span><span class="p">[</span><span class="n">offset</span><span class="o">..</span><span class="p">])</span><span class="nf">.to_string</span><span class="p">()));</span>
        <span class="p">}</span>

        <span class="k">let</span> <span class="n">matched_strings_and_types</span> <span class="o">=</span> <span class="n">matched_patterns_index</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">pattern_index</span><span class="p">|</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">pattern_str</span> <span class="o">=</span> <span class="n">PATTERN_MAP</span><span class="nf">.keys</span><span class="p">()</span><span class="nf">.nth</span><span class="p">(</span><span class="n">pattern_index</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
            <span class="k">let</span> <span class="n">token_type</span> <span class="o">=</span> <span class="n">PATTERN_MAP</span><span class="nf">.get</span><span class="p">(</span><span class="n">pattern_str</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
            <span class="k">let</span> <span class="n">matched_string</span> <span class="o">=</span> <span class="nn">Regex</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">pattern_str</span><span class="p">)</span>
                <span class="nf">.expect</span><span class="p">(</span><span class="s">"Invalid regex pattern -- This should never happen"</span><span class="p">)</span>
                <span class="nf">.find</span><span class="p">(</span><span class="o">&amp;</span><span class="n">input</span><span class="p">[</span><span class="n">offset</span><span class="o">..</span><span class="p">])</span>
                <span class="nf">.unwrap</span><span class="p">()</span>
                <span class="nf">.as_str</span><span class="p">();</span>
            <span class="p">(</span><span class="n">token_type</span><span class="p">,</span> <span class="n">matched_string</span><span class="p">)</span>
        <span class="p">});</span>

        <span class="k">let</span> <span class="n">longest_match</span> <span class="o">=</span> <span class="n">matched_strings_and_types</span>
            <span class="nf">.max_by_key</span><span class="p">(|(</span><span class="n">_tokentype</span><span class="p">,</span> <span class="n">matched</span><span class="p">)|</span> <span class="n">matched</span><span class="nf">.len</span><span class="p">())</span>
            <span class="nf">.expect</span><span class="p">(</span><span class="s">"Something should've matched"</span><span class="p">);</span>

        <span class="k">let</span> <span class="p">(</span><span class="n">token_type</span><span class="p">,</span> <span class="n">matched_string</span><span class="p">)</span> <span class="o">=</span> <span class="n">longest_match</span><span class="p">;</span>
        <span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="n">offset</span><span class="p">;</span>
        <span class="k">let</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">matched_string</span><span class="nf">.len</span><span class="p">();</span>
        <span class="k">let</span> <span class="n">r</span><span class="err">#</span><span class="k">type</span> <span class="o">=</span> <span class="o">*</span><span class="n">token_type</span><span class="p">;</span>

        <span class="n">tokens</span><span class="nf">.push</span><span class="p">(</span><span class="n">Token</span> <span class="p">{</span>
            <span class="n">r</span><span class="err">#</span><span class="k">type</span><span class="p">,</span>
            <span class="n">start</span><span class="p">,</span>
            <span class="n">end</span><span class="p">,</span>
            <span class="n">content</span><span class="p">:</span> <span class="n">matched_string</span><span class="nf">.to_string</span><span class="p">(),</span>
        <span class="p">});</span>

        <span class="n">offset</span> <span class="o">=</span> <span class="n">end</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="nf">Ok</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <p>The regexset returns a iterable of indexes of the matched patterns, and we can then get the matched string from the input string. We then find the longest match, and create a token from that match. The offset is then moved to the end of the matched string, and the process continues until the end of the input string.</p> <h3 id="issues-with-this-implementation">Issues with this implementation</h3> <p>The implementation is quite elegant at the first glance - to add more tokens, we just add them to the <code class="language-plaintext highlighter-rouge">TokenType</code> map, and the <code class="language-plaintext highlighter-rouge">PATTERN_MAP</code>. The lexer token types are ordered by default in the TokenType map (the latter tokens in the enum have more precedence than the upper tokens), so we don‚Äôt need to worry about breaking ties. The issues with this implementation are:</p> <ul> <li>Usage of RegexSet and Regex is not very performant.</li> <li>In most cases, the conflicts arise with matching ‚Äúidentifier‚Äù and ‚Äútoken‚Äù types from my experience. It is not worth it to use Regex for this case.</li> <li>We may not want to ‚Äúeat‚Äù whitespace all the time - we have cases like matching string literals where we would like to keep the whitespace (albeit this can be solved by adding a new regex type for string literal).</li> </ul> <p>I glossed over the lexer implementation of lexers that <a href="https://brunocalza.me/writing-a-simple-lexer-in-rust/" rel="external nofollow noopener" target="_blank">other people have done</a> and this implementation looks unnecessarily brute-forcy.</p> <h2 id="writing-a-better-lexer">Writing a better lexer.</h2> <p>I want the implementation of the lexer to be more performant, and more conventional - in tune with what people in the industry actually do instead of creating a large messy RegexSet to hide from the actual implementation. If you think about it, it‚Äôs really simple - the conflicts generally arise when matching inputs like ‚Äúif‚Äù and ‚Äúidentifier‚Äù, or ‚Äú&gt;=‚Äù and ‚Äú&gt;‚Äù and ‚Äú=‚Äù.</p> <p>The lexer in this case will become a simple state matchine we can code by-hand. We start by reusing the token_type enum and token struct from before, and defining a lexer struct. The struct looks like this:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">struct</span> <span class="n">Lexer</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">input</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">[</span><span class="nb">char</span><span class="p">],</span>
    <span class="n">position</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <p>Since rust has excellent default support for Unicode characters, we can use <code class="language-plaintext highlighter-rouge">char</code> type. Next, we begin by defining some basic operations on the lexer struct.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">LexerResult</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">LexerError</span><span class="o">&gt;</span><span class="p">;</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="n">Lexer</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">pub</span> <span class="k">fn</span> <span class="nf">new</span><span class="p">(</span><span class="n">input</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">[</span><span class="nb">char</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="n">Lexer</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="n">Lexer</span> <span class="p">{</span> <span class="n">input</span><span class="p">,</span> <span class="n">position</span><span class="p">:</span> <span class="mi">0</span> <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">peek</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">char</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="k">if</span> <span class="k">self</span><span class="py">.position</span> <span class="o">&gt;=</span> <span class="k">self</span><span class="py">.input</span><span class="nf">.len</span><span class="p">()</span> <span class="p">{</span>
            <span class="nb">None</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nf">Some</span><span class="p">(</span><span class="k">self</span><span class="py">.input</span><span class="p">[</span><span class="k">self</span><span class="py">.position</span><span class="p">])</span>
        <span class="p">};</span>

        <span class="n">res</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">advance</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">LexerResult</span><span class="o">&lt;</span><span class="nb">char</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">if</span> <span class="k">self</span><span class="py">.position</span> <span class="o">&gt;=</span> <span class="k">self</span><span class="py">.input</span><span class="nf">.len</span><span class="p">()</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="nn">LexerError</span><span class="p">::</span><span class="n">EndOfInput</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="nf">Ok</span><span class="p">(</span><span class="k">self</span><span class="py">.input</span><span class="p">[</span><span class="k">self</span><span class="py">.position</span><span class="p">]);</span>
        <span class="k">self</span><span class="py">.position</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">res</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">eat_whitespace</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">LexerResult</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">while</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.peek</span><span class="p">()</span> <span class="p">{</span>
            <span class="k">if</span> <span class="o">!</span><span class="n">ch</span><span class="nf">.is_whitespace</span><span class="p">()</span> <span class="p">{</span>
                <span class="k">break</span><span class="p">;</span>
            <span class="p">}</span>

            <span class="k">let</span> <span class="n">_</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.advance</span><span class="p">()</span><span class="o">?</span><span class="p">;</span> <span class="c1">// Discard the whitespace.</span>
        <span class="p">}</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>All the functions are pretty self-explanatory. We begin by creating a lexer that tracks the position in the input string. We can peek at the current character, advance the position, and eat whitespace.</p> <p>Now we need a function that actuallly does the lexing.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">fn</span> <span class="nf">lex</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">LexerResult</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">tokens</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

    <span class="c1">// Start, eat whitespace.</span>
    <span class="k">self</span><span class="nf">.eat_whitespace</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="c1">// Match the first character.</span>
    <span class="k">while</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">current_char</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.peek</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">match</span> <span class="n">current_char</span> <span class="p">{</span>
            <span class="sc">'a'</span><span class="o">..</span><span class="sc">'z'</span> <span class="p">|</span> <span class="sc">'A'</span><span class="o">..</span><span class="sc">'Z'</span> <span class="p">|</span> <span class="sc">'_'</span> <span class="k">=&gt;</span> <span class="n">tokens</span><span class="nf">.push</span><span class="p">(</span><span class="k">self</span><span class="nf">.match_identifier_or_keyword</span><span class="p">()</span><span class="o">?</span><span class="p">),</span>
            <span class="n">symb</span> <span class="k">=&gt;</span> <span class="p">{</span>
                <span class="k">let</span> <span class="n">tok_type</span> <span class="o">=</span> <span class="k">match</span> <span class="n">symb</span> <span class="p">{</span>
                    <span class="sc">'.'</span> <span class="k">=&gt;</span> <span class="nn">TokenType</span><span class="p">::</span><span class="n">Dot</span><span class="p">,</span>
                    <span class="n">_</span> <span class="k">=&gt;</span> <span class="p">{</span>
                        <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="nn">LexerError</span><span class="p">::</span><span class="nf">PartiallyMatchedInput</span><span class="p">(</span>
                            <span class="n">tokens</span><span class="p">,</span>
                            <span class="k">self</span><span class="py">.input</span><span class="p">[</span><span class="k">self</span><span class="py">.position</span><span class="o">..</span><span class="p">]</span><span class="nf">.iter</span><span class="p">()</span><span class="nf">.collect</span><span class="p">(),</span>
                        <span class="p">))</span>
                    <span class="p">}</span>
                <span class="p">};</span>

                <span class="n">tokens</span><span class="nf">.push</span><span class="p">(</span><span class="n">Token</span> <span class="p">{</span>
                    <span class="n">start</span><span class="p">:</span> <span class="k">self</span><span class="py">.position</span><span class="p">,</span>
                    <span class="n">end</span><span class="p">:</span> <span class="k">self</span><span class="py">.position</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">token_type</span><span class="p">:</span> <span class="n">tok_type</span><span class="p">,</span>
                    <span class="n">content</span><span class="p">:</span> <span class="nn">String</span><span class="p">::</span><span class="nf">from</span><span class="p">(</span><span class="k">self</span><span class="nf">.advance</span><span class="p">()</span><span class="o">?</span><span class="p">),</span>
                <span class="p">});</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="k">self</span><span class="nf">.eat_whitespace</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// End, eat all whitespace</span>
    <span class="k">self</span><span class="nf">.eat_whitespace</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="k">return</span> <span class="nf">Ok</span><span class="p">(</span><span class="n">tokens</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>The lex function starts off by creating the return array of tokens. Then we discard all whitespace until we hit a char we can parse. Based on the char at the start of the input stream, we can match either an identifier/keyword, or a symbol (our symbol is limited to just ‚Äò.‚Äô for now). The match_identifier_or_keyword function is a helper function that matches the identifier or keyword.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    <span class="k">fn</span> <span class="nf">match_identifier_or_keyword</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">LexerResult</span><span class="o">&lt;</span><span class="n">Token</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="k">self</span><span class="py">.position</span><span class="p">;</span>
        <span class="k">let</span> <span class="n">startsym</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.advance</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">buffer</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">from</span><span class="p">(</span><span class="n">startsym</span><span class="p">);</span>
        
        <span class="k">while</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.peek</span><span class="p">()</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">ch</span><span class="nf">.is_ascii_alphanumeric</span><span class="p">()</span> <span class="p">||</span> <span class="n">ch</span> <span class="o">==</span> <span class="sc">'_'</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">ch</span><span class="nf">.is_whitespace</span><span class="p">()</span> <span class="p">{</span>
                <span class="n">buffer</span><span class="nf">.push</span><span class="p">(</span><span class="k">self</span><span class="nf">.advance</span><span class="p">()</span><span class="o">?</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="k">break</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="k">let</span> <span class="n">kwmatch</span> <span class="o">=</span> <span class="k">match</span> <span class="n">buffer</span><span class="nf">.as_ref</span><span class="p">()</span> <span class="p">{</span>
            <span class="s">"if"</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="nn">TokenType</span><span class="p">::</span><span class="n">KwIf</span><span class="p">),</span>
            <span class="n">_</span> <span class="k">=&gt;</span> <span class="nb">None</span><span class="p">,</span>
        <span class="p">};</span>

        <span class="k">return</span> <span class="nf">Ok</span><span class="p">(</span><span class="n">Token</span> <span class="p">{</span>
            <span class="n">start</span><span class="p">,</span>
            <span class="n">end</span><span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">buffer</span><span class="nf">.len</span><span class="p">(),</span>
            <span class="n">token_type</span><span class="p">:</span> <span class="n">kwmatch</span><span class="nf">.unwrap_or</span><span class="p">(</span><span class="nn">TokenType</span><span class="p">::</span><span class="n">Identifier</span><span class="p">),</span>
            <span class="n">content</span><span class="p">:</span> <span class="n">buffer</span><span class="p">,</span>
        <span class="p">});</span>
    <span class="p">}</span>
</code></pre></div></div> <p>The function begins by reading off the start char into a string itself. Then until we have ascii alphanumeric char or ‚Äú_‚Äù in the input stream, we will continue to push it into the buffer. When we hit a non-alphanumeric char, we break out of the loop and check if the buffer is a keyword. If it is, we return the keyword token, else we return the identifier token.</p> <p>The lexer is now complete. The complete lexer code looks like <a href="https://gist.github.com/sandeshbhusal/5de659c5081b42eaf668e1e5bf090feb" rel="external nofollow noopener" target="_blank">this</a>.</p> <h2 id="concluding-remarks">Concluding remarks</h2> <p>I had a lot of fun writing (and rewriting) this lexer. While the task of writing something by hand might sound daunting at first, and we might immediately want to run off to write code with libraries like <code class="language-plaintext highlighter-rouge">Regex</code>, it can be beneficial to write code by hand sometimes to solidify understanding and challenge oneself. The lexer implementation above is very simple - we can improve further on it, e.g. by adding support for string literals, comments, and other symbols. The lexer can be extended to support more complex languages, and can be used as a base for writing a parser for the language. There is also the opportunity for performance optimization - we could remove all memory allocations and use slices instead of strings, and we could also use a more efficient data structure to store the tokens. However, those are topics for another day.</p> <p>I hope you enjoyed reading this post. If you have any feedback, feel free to reach out to me on <a href="https://linkedin.com/in/sandeshbhusal" rel="external nofollow noopener" target="_blank">LinkedIn</a>. I‚Äôm always open to feedback and suggestions. Until next time, happy coding! üöÄ</p> </div> </article> </div> </div> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> ¬© Copyright 2025 Sandesh Bhusal. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>